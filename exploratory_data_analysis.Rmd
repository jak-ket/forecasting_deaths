---
title: "R Notebook"
output: html_notebook
---

```{r}
source("functions.R")
```


```{r}
cases_raw <- read.csv("./data-truth/truth_RKI-Incident Cases by Age_Germany.csv")
deaths_raw <- read.csv("./data-truth/truth_RKI-Incident Deaths by Age_Germany.csv")
```

```{r}
names(cases_raw)
names(deaths_raw)
```
```{r}
# restrict to Germany and useful columns only
cases <- subset(cases_raw, location_name=="Germany", select=c(date, age_group, value))
deaths <- subset(deaths_raw, location_name=="Germany", select=c(date, age_group, value))

# reset index
row.names(cases) <- NULL
row.names(deaths) <- NULL
```

## Basic analysis of time series data

```{r}
# get age groups
unique(cases["age_group"])
unique(deaths["age_group"])

ags <- unname(unlist(unique(deaths["age_group"])))
ags
```

```{r}
head(cases)
tail(cases)

head(deaths)
tail(deaths)

# same time horizon : 2020-03-25 -> 2021-03-16

dim(cases)
dim(deaths)
```

### Why does number of entries differ by 399?

```{r}
length(unique(cases$date))
length(unique(deaths$date))
all(unique(deaths$date) == unique(cases$date))
# same 357 dates

start_date <- as.Date(cases$date[1])
end_date <- as.Date(cases$date[dim(cases)[1]])
end_date - start_date + 1 # == 357
# all dates in horizon seem to be covered

# guess: not every date contains all age strata; especially death data doesnt
```


```{r}
# get time series in wide format / age groups in rows
cases_wide <- setNames(reshape(cases, idvar="date", timevar="age_group", direction = "wide"), c("date", ags))
deaths_wide <- setNames(reshape(deaths, idvar="date", timevar="age_group", direction = "wide"), c("date", ags))

cases_wide$date <- as.Date(cases_wide$date)
deaths_wide$date <- as.Date(deaths_wide$date)

row.names(cases_wide) <- NULL
row.names(deaths_wide) <- NULL
```

## Visual Exploration

```{r}
boxplot(cases_wide[-1])
boxplot(deaths_wide[-1])
```


```{r}
colours <- 1:length(ags)
line_width <- 2
columns <- c(ags[3],ags[6])
plot_type <- "l"

matplot(cases_wide$date, cases_wide[,columns], 
        pch=1, type=plot_type, lwd=line_width, col=colours, main="cases per age stratum")
legend('topleft',legend=columns, col=colours, lwd=line_width)

matplot(deaths_wide$date, deaths_wide[,columns], 
        pch=1, type=plot_type, lwd=line_width, col=colours, main="deaths per age stratum")
legend('topleft',legend=columns, col=colours, lwd=line_width)
```
```{r}
# check NAs
for (ag in ags){
  print(any(is.na(cases_wide[,ag])))
}

for (ag in ags){
  print(any(is.na(deaths_wide[,ag])))
}

# => NAs in death data
```

```{r}
# replace NAs with zero
cases_wide[is.na(cases_wide)] <- 0
deaths_wide[is.na(deaths_wide)] <- 0
```

## explore cumulative death and case counts per stratum

```{r}
cases_ag_sum <- numeric(length = length(ags))
deaths_ag_sum <- numeric(length = length(ags))

for (i in 1:length(ags)){
  cases_ag_sum[i] <- sum(cases_wide[,ags[i]])
  deaths_ag_sum[i] <- sum(deaths_wide[,ags[i]])
} 

cd_sums <- data.frame(ags, cases_ag_sum, deaths_ag_sum)

cd_sums

# plot(cases_ag_sum)
# xticks <- 1:length(ags)
# axis(side=1, at=xticks, labels = FALSE)
# text(x=xticks, labels=ags, pos=1, xpd=T, )
# points(deaths_ag_sum, col="red")
```
## explore lag between cases and deaths 

```{r}
# whole time series
source("functions.R")

max_cor_lags <- numeric(length = length(ags))
i <- 1
for (ag in ags){
  # prepare 7-day cumulated series
  cases_rolsum <- rolling_sum(cases_wide[,ag])
  deaths_rolsum <- rolling_sum(deaths_wide[,ag])
  
  # get lag that maximizes correlation between deaths and cases
  plot_title <- paste("Correlation btw. lagged death and case series of ", ag)
  lag <- max_cor_lag(cases_rolsum, deaths_rolsum, lags=10:50, plot_out=T, plot_title=plot_title)#, print_out=T)
  max_cor_lags[i] <- lag
  print(paste("age group: ", ag, " - lag maximizing cor: ", lag))
  i <- i + 1
} 

# split time series and analyze time dependence on lag with highest cor
# 1:175 vs 176:351
splits <- list("split1"=c(1:175), "split2"=c(176:351)) 

source("functions.R")
for (split in splits){
  print(paste("Time Points: ", split[1], "-", split[length(split)]))
  for (ag in ags){
    # prepare 7-day cumulated series
    cases_rolsum <- rolling_sum(cases_wide[,ag])[split]
    deaths_rolsum <- rolling_sum(deaths_wide[,ag])[split]
    
    # get lag that maximizes correlation between deaths and cases
    plot_title <- paste("Correlation btw. lagged death and case series of ", ag)
    lag <- max_cor_lag(cases_rolsum, deaths_rolsum, lags=10:40, plot_out=T, plot_title=plot_title)#, print_out=T)
    print(paste("age group: ", ag, " - lag maximizing cor: ", lag))
  } 
}

# large differences in max cor lags between different splits

```


```{r}
# calculate fatality rates per stratum based on whole time span
source("functions.R")

fat_rates <- numeric(length = length(ags))
for (i in 1:length(ags)){
  ag <- ags[i]
  lag <- max_cor_lags[i]
  
  cases_rolsum <- rolling_sum(cases_wide[,ag])
  deaths_rolsum <- rolling_sum(deaths_wide[,ag])
  
  lagged_ts <- get_lagged_ts(cases_rolsum, deaths_rolsum, lag=lag)
  cases_rs_lagged <- lagged_ts[,1]
  deaths_rs_lagged <- lagged_ts[,2]
  
  scale <- max(cases_rs_lagged)/max(deaths_rs_lagged)*0.5
  plot(cases_rs_lagged/scale, main=paste("death/case series shifted by max_cor_lag for ", ag))
  lines(deaths_rs_lagged)
  
  fat_rate <- calc_fat_rate(deaths_rs_lagged, cases_rs_lagged)
  fat_rates[i] <- fat_rate
  
  print(paste("Age group: ", ag, "- Fatality rate: ", fat_rate))
}

```

## fatality rate over time

```{r}
source("functions.R")

window <- 7
for (i in 1:length(ags)){
  ag <- ags[i]
  lag <- max_cor_lags[i]
  
  cases_rolsum <- rolling_sum(cases_wide[,ag], window = window)
  deaths_rolsum <- rolling_sum(deaths_wide[,ag], window = window)
  
  lagged_ts <- get_lagged_ts(cases_rolsum, deaths_rolsum, lag=lag)
  cases_rs_lagged <- lagged_ts[,1]
  deaths_rs_lagged <- lagged_ts[,2]
  
  l <- dim(cases_wide)[1]
  dates <- cases_wide[(l-length(cases_rs_lagged)+1):l,"date"]
  title <- paste("Case fatality rate over time with median: group", ag, ", lag", lag)
  frs <- calc_fat_rate(deaths_rs_lagged, cases_rs_lagged, avg=F)
  plot(dates, frs, main=title, type="b")
  abline(a=median(frs), b=0, col="red")
}

```


## Explore alternative data sources

### DIVI - Deutsche Interdisziplinäre Vereinigung für Intensiv- und Notfallmedizin
* ICU
* Ventilated

```{r}
# divi data
divi_icu_raw <- read.csv("./data-truth/truth_DIVI-Current ICU_Germany.csv")
divi_vent_raw <- read.csv("./data-truth/truth_DIVI-Current Ventilated_Germany.csv")

# restrict to Germany and useful columns only
divi_icu <- subset(divi_icu_raw, location_name=="Germany", select=c(date, value))
divi_vent <- subset(divi_vent_raw, location_name=="Germany", select=c(date, value))
divi_icu$date <- as.Date(divi_icu$date)
divi_vent$date <- as.Date(divi_vent$date)

colnames(divi_icu) <- c("date", "icu")
colnames(divi_vent) <- c("date", "vent")

divi <- merge(divi_icu, divi_vent, by="date")

# calculate deaths and cases across age groups
cases_sum <- data.frame(cases_wide$date, rowSums(cases_wide[,-1]))
deaths_sum <- data.frame(deaths_wide$date, rowSums(deaths_wide[,-1]))
colnames(cases_sum) <- c("date", "cases")
colnames(deaths_sum) <- c("date", "deaths")

cases_deaths <- merge(cases_sum, deaths_sum, by="date")

# get divi data in same df as deaths and cases
divicd <- merge(divi, cases_deaths, by="date")
```


```{r}
source("functions.R")
# look at all lag-correlations plots (exclude date column)

for(col1 in colnames(divicd)[-1]){
  for(col2 in colnames(divicd)[-1]){
    if(col1 != col2){
      title <- paste("Cor-lag plot between", col1, "and", col2)
    max_cor_lag(divicd[,col1], divicd[,col2], lags=1:40, rolsum=T, window=7, plot_title = title) 
    }
  }
}


```



## forecasting deaths

### naive non-probabilistic approach

```{r}
# forecasting deaths based on max_cor_lag and fatality rate
# input: case time series, max_cor_lag, fat_rate, horizon
# output: forecast of deaths for horizon time period from last observation in input series
forecast_deaths_naive <- function(cases, deaths, lag, horizon, window=7){
  forecasts <- numeric(length=horizon)

  # get rolled sums
  cases_rolsum <- rolling_sum(cases, window = window)
  deaths_rolsum <- rolling_sum(deaths, window = window)
  
  # calculate time varying case fatality rates
  lagged_ts <- get_lagged_ts(cases_rolsum, deaths_rolsum, lag=lag)
  cases_rs_lagged <- lagged_ts[,1]
  deaths_rs_lagged <- lagged_ts[,2]
  cfrs <- deaths_rs_lagged/cases_rs_lagged
  
  # take avg of last window fatality rates
  cfr <- mean(cfrs[(length(cfrs)-window):length(cfrs)])
  print(paste("Used case fatality rate cfr =", cfr))
  
  for(h in 1:horizon){
    forecasts[h] <- cases_rolsum[(length(cases)-lag+h)]/window * cfr
  }
  return(forecasts)
}
# TODO: 
# calculate max_cor_lag and fat_rate based on a sliding window
# output format: data frame with dates and col names
# rolling sum of case number: params for window size


```


```{r}
# test
ag_nr <- 5
ag <- ags[ag_nr]
fc <- forecast_deaths_naive(cases_wide[,ag], deaths_wide[,ag], lag=max_cor_lags[ag_nr], horizon=10, window=7)
```

```{r}
plot(c(deaths_wide[340:l,ag], fc))
```

### probabilistic approach


```{r}
fit_params <- function(cases_lagged, deaths_truth, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){
    
  wis_sum <- function(par){
    size <- par["size"]
    cfr <- par["cfr"]

    # estimate deaths with case fatality rate (cfr)
    deaths_pred = cfr * cases_lagged
    
    sum(wis_nb(x = deaths_truth, mu = deaths_pred, size = size, p = p))
  }
  
  # optimize
  # initial values
  size_start <- 3
  cfr_start <- 0.05
  # lower bounds
  lb_size <- 10^-6
  lb_cfr <- 10^-6
  lower_bounds <- c(lb_size,lb_cfr)
  # upper bounds
  # ub_size <- 
  # ub_cfr <- 
  opt <- optim(par = c(size = size_start, cfr = cfr_start), method="L-BFGS-B", lower=lower_bounds, fn = wis_sum)

  return(opt)
}
```


```{r}
# only use data from September on due to instability before
start <- as.Date("2020-09-01")
end <- as.Date("2020-12-15")
cases_trunc <- cases_wide[cases_wide[,"date"]>=start & cases_wide[,"date"]<=end,]
deaths_trunc <- deaths_wide[deaths_wide[,"date"]>=start & deaths_wide[,"date"]<=end,]

# params
ag_nr <- 5 # age group
ag <- ags[ag_nr]
lags <- 15:25
window <- 7

# subset date and age group
cases_ <- cases_trunc[,c("date",ag)]
deaths_ <- deaths_trunc[,c("date",ag)]

# compute rolling sums; first window-1 dates are excluded
start_after_rolsum <- start+window-1
cases_[cases_[,"date"]>=(start_after_rolsum),ag] <- rolling_sum(cases_[,ag], window = window)
deaths_[deaths_[,"date"]>=(start_after_rolsum),ag] <- rolling_sum(deaths_[,ag], window = window)
cases_ <- cases_[cases_[,"date"]>=(start_after_rolsum),]
deaths_ <- deaths_[deaths_[,"date"]>=(start_after_rolsum),]


# save param values and objective value per lag
param_names <- c("size", "cfr")
results <- matrix(data = NA, nrow=length(lags), ncol=1+length(param_names)+1) 
colnames(results) <- c("lag", param_names, "value")

for (i in 1:length(lags)){
  lag <- lags[i]

  # based on current lag values, compute feasible death forecast Saturdays
  saturdays <- weekdays(deaths_[,"date"]) == "Samstag"
  deaths_sat <- deaths_[saturdays & deaths_[,"date"] >= (start_after_rolsum+lag),]
  
  # compute lagged cases
  cases_lagged_dates <- deaths_sat[,"date"]-lag
  cases_lagged <- cases_[cases_[,"date"] %in% cases_lagged_dates,]
  
  # get time series without dates
  deaths_sat_ts <- deaths_sat[,ag]
  cases_lagged_ts <- cases_lagged[,ag]
  
  stopifnot(length(cases_lagged_ts) == length(deaths_sat_ts))
  print(paste("Fitting on", length(cases_lagged_ts), "data points."))
  
  # compute parameters
  res <- fit_params(cases_lagged_ts, deaths_sat_ts)
  
  # save results
  results[i,] <- c(lag, res$par, res$value)
}

overall_results <- results[which.min(results[,"value"]),]
overall_results

```


```{r}
plot(results[,"lag"], results[,"value"], type="b")
```


```{r}

# calculate death distribution forecast for given date  
death_forecast <- function(cases_rolsum, fc_date, params, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){
  # cases_rolsum <- cases_
  
  lag <- params[1]
  size <- params[2]
  cfr <- params[3]
  
  # get lagged case count
  end_date <- cases_rolsum[dim(cases_rolsum)[1],"date"]
  lag_date <- as.Date(fc_date) - lag
  stopifnot(lag_date <= end_date)
  case_count <- cases_rolsum[cases_rolsum[,"date"]==lag_date,ag]
  ag
  case_count
  # compute death forecast
  mu <- cfr * case_count
  mu
  # get quantiles according to estimated negative binomial distribution
  q <- qnbinom(p, mu = mu, size = size)
  names(q) <- p 
  return(q)
}

params <- unname(overall_results[-length(overall_results)])

fc_date <- "2020-12-31"

fc <- death_forecast(cases_, fc_date, params)
fc
# PROBLEM
# case fatality rate is not stable; should be fitted on moving window! 
```

```{r}


plot(cases_, main="Cases")
plot(deaths_, main="Deaths")

# add forecast data
deaths_w_fc <- rbind(deaths_, c(fc_date, fc["0.5"]))
dates_ <- c(deaths_[dim(deaths_)[1],"date"], fc_date)
upper_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.99"])
lower_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.01"])

plot(deaths_w_fc, ylim=c(min(0, fc["0.01"]), max(as.integer(max(deaths_[,ag])), fc["0.99"])), main="Deaths with forecast")
points(as.Date(fc_date), fc["0.5"], col="red")
points(as.Date(fc_date), fc["0.01"], col="red")
points(as.Date(fc_date), fc["0.99"], col="red")
poly_dates <- c(deaths_[dim(deaths_)[1],"date"], fc_date, fc_date)
poly_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.99"], fc["0.01"])
polygon(poly_dates, poly_values, col="darksalmon", border = FALSE)
lines(dates_, upper_values, col="red")
lines(dates_, lower_values, col="red")

```


```{r}
# 
ag_nr <- 5 # age group
ag <- ags[ag_nr]

lags <- 10:30

fc <- forecast_deaths_naive(cases_wide[,ag], deaths_wide[,ag], lag=max_cor_lags[ag_nr], horizon=10, window=7)
```










