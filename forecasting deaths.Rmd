---
title: "Forecasting deaths"
output: html_notebook
---


```{r}
# set up
setwd("~/forecast_hub/forecasting_deaths")
Sys.setlocale(category = "LC_TIME", locale = "English")
source("functions.R")
```

## prepare data

```{r}
cases_raw <- read.csv("./data-truth/truth_RKI-Incident Cases by Age_Germany.csv")
deaths_raw <- read.csv("./data-truth/truth_RKI-Incident Deaths by Age_Germany.csv")

# restrict to Germany and useful columns only
cases <- subset(cases_raw, location_name=="Germany", select=c(date, age_group, value))
deaths <- subset(deaths_raw, location_name=="Germany", select=c(date, age_group, value))

# reset index
row.names(cases) <- NULL
row.names(deaths) <- NULL

# get age groups
ags <- unname(unlist(unique(deaths["age_group"])))
ags

# get time series in wide format / age groups in rows
cases_wide <- setNames(reshape(cases, idvar="date", timevar="age_group", direction = "wide"), c("date", ags))
deaths_wide <- setNames(reshape(deaths, idvar="date", timevar="age_group", direction = "wide"), c("date", ags))

cases_wide$date <- as.Date(cases_wide$date)
deaths_wide$date <- as.Date(deaths_wide$date)

row.names(cases_wide) <- NULL
row.names(deaths_wide) <- NULL
```

## forecast deaths


```{r}

#' Evaluate WIS of a negative binomial distribution
#' @param x the vector of observations
#' @param size the vector of size parameters of the negative binomial distribution
#' @param mu the vector of expectations of the negative binomial distribution
#' @param p the vector of quantile levels used in the computation of the WIS
wis_nb <- function(x, size, mu, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){
  # check input
  # print(paste(size, mu))
  if(any(mu <= 0) | any(size <= 0)) stop("mu and size need to be positive.")
  if(length(mu) == 1) mu <- rep(mu, length(x))
  if(length(size) == 1) size <- rep(size, length(x))
  if(length(mu) != length(x) | length(size) != length(x)) stop("mu and size need to be either of length 1 or the same length as x.")  
  # function to evaluate wis for x[i] and parameters mu[i] and size[i]
  wis_nb.i <- function(i){
    # compute quantiles
    q <- qnbinom(p, mu = mu[i], size = size[i])
    # evaluate WIS (see eq 4 here https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618#sec001)
    mean(2*((x[i] <= q) - p)*(q - x[i]))
  }  
  # apply to vector
  sapply(seq_along(x), wis_nb.i)
}


fit_params <- function(cases_lagged, deaths_truth, init_values, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){
    
  wis_sum <- function(par){
    # retransform with exp to render params positive
    size <- exp(par["log_size"])
    cfr <- exp(par["log_cfr"])

    # estimate deaths with case fatality rate (cfr)
    deaths_pred = cfr * cases_lagged
    # deaths_pred = covariates %*% par[-1]
    
    # print(paste(size, cfr, cases_lagged, deaths_pred))
    
    sum(wis_nb(x = deaths_truth, mu = deaths_pred, size = size, p = p))
  }
  
  # initial values (log-transformed)
  if (any(is.na(init_values))){
    log_size_start <- log(3)
    log_cfr_start <- log(0.05)
  } else {
    log_size_start <- log(init_values[1])
    log_cfr_start <- log(init_values[2])
  }
  
  # lower bounds
  # lb_size <- 10^-6
  # lb_cfr <- 10^-6
  # lower_bounds <- c(lb_size,lb_cfr)
  # upper bounds
  # ub_size <- 
  # ub_cfr <- 
  
  # optimization
  # params are log-transformed 
  opt <- optim(par = c(log_size = log_size_start, log_cfr = log_cfr_start), fn = wis_sum)#,method="BFGS") #method="L-BFGS-B", lower=lower_bounds)
  
  # retransform
  opt$par <- exp(opt$par)
  
  return(opt)
}
```


```{r}

## parameters ##############

# age group
ag_nr <- 6
ag <- ags[ag_nr]
# set of lags to optimize over
lags <- 10:35
# window for rolling sum (smoothing)
window <- 7
# select training period 
start <- as.Date("2020-12-01")

end <- NA # give exact date or NA to choose end of time series

############################

# truncate data for training period
if(is.na(end)){end <- cases_wide[dim(cases_wide)[1],"date"]}
cases_trunc <- cases_wide[cases_wide[,"date"]>=start & cases_wide[,"date"]<=end,]
deaths_trunc <- deaths_wide[deaths_wide[,"date"]>=start & deaths_wide[,"date"]<=end,]

# subset date and age group
cases_ <- cases_trunc[,c("date",ag)]
deaths_ <- deaths_trunc[,c("date",ag)]

# compute rolling sums; first window-1 dates are excluded
start_after_rolsum <- start+window-1
cases_[cases_[,"date"]>=(start_after_rolsum),ag] <- rolling_sum(cases_[,ag], window = window)
deaths_[deaths_[,"date"]>=(start_after_rolsum),ag] <- rolling_sum(deaths_[,ag], window = window)
cases_ <- cases_[cases_[,"date"]>=(start_after_rolsum),]
deaths_ <- deaths_[deaths_[,"date"]>=(start_after_rolsum),]


# save param values and objective value per lag
param_names <- c("size", "cfr")
results <- matrix(data = NA, nrow=length(lags), ncol=1+length(param_names)+1) 
colnames(results) <- c("lag", param_names, "value")

for (i in 1:length(lags)){
  lag <- lags[i]

  # based on current lag values, compute feasible death forecast Saturdays
  saturdays <- weekdays(deaths_[,"date"]) == "Saturday"
  deaths_sat <- deaths_[saturdays & deaths_[,"date"] >= (start_after_rolsum+lag),]
  
  # compute lagged cases
  cases_lagged_dates <- deaths_sat[,"date"]-lag
  cases_lagged <- cases_[cases_[,"date"] %in% cases_lagged_dates,]
  
  # get time series without dates
  deaths_sat_ts <- deaths_sat[,ag]
  cases_lagged_ts <- cases_lagged[,ag]
  
  stopifnot(length(cases_lagged_ts) == length(deaths_sat_ts))
  print(paste("Fitting on", length(cases_lagged_ts), "data points."))
  
  # starting values for optimization
  if (i >= 2){
    init_values <- results[i,param_names]
  } else {
    init_values <- NA
  }
  
  # compute parameters
  res <- fit_params(cases_lagged_ts, deaths_sat_ts, init_values)
  
  # save results
  results[i,] <- c(lag, res$par, res$value)
}

overall_results <- results[which.min(results[,"value"]),]

plot(results[,"lag"], results[,"value"], type="b", main = ag)

overall_results
```


```{r}
# calculate death distribution forecast for given date  
death_forecast <- function(cases_rolsum, fc_date, params, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){

  # unpack parameters
  lag <- params[1]
  size <- params[2]
  cfr <- params[3]
  
  # get lagged case count
  end_date <- cases_rolsum[dim(cases_rolsum)[1],"date"]
  lag_date <- as.Date(fc_date) - lag
  stopifnot(lag_date <= end_date) # can only forecast lag days into future
  case_count <- cases_rolsum[cases_rolsum[,"date"]==lag_date,ag]

  # compute death forecast
  mu <- cfr * case_count

  # get quantiles according to estimated negative binomial distribution
  q <- qnbinom(p, mu = mu, size = size)
  names(q) <- p 
  
  return(q)
}

# test forecast
params <- unname(overall_results[-length(overall_results)])
fc_date <- "2021-04-03"
fc <- death_forecast(cases_, fc_date, params)
fc

```


```{r}
# visualize forecast

plot(cases_, main="Cases")
plot(deaths_, main="Deaths")

deaths_w_fc <- rbind(deaths_, c(fc_date, fc["0.5"]))
dates_ <- c(deaths_[dim(deaths_)[1],"date"], fc_date)
upper_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.99"])
lower_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.01"])

plot(deaths_w_fc, ylim=c(min(0, fc["0.01"]), max(as.integer(max(deaths_[,ag])), fc["0.99"])), main="Deaths with forecast")
points(as.Date(fc_date), fc["0.5"], col="red")
points(as.Date(fc_date), fc["0.01"], col="red")
points(as.Date(fc_date), fc["0.99"], col="red")
poly_dates <- c(deaths_[dim(deaths_)[1],"date"], fc_date, fc_date)
poly_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.99"], fc["0.01"])
polygon(poly_dates, poly_values, col="darksalmon", border = FALSE)
lines(dates_, upper_values, col="red")
lines(dates_, lower_values, col="red")

```



