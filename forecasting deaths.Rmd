---
title: "Forecasting deaths"
output: html_notebook
---


```{r}
# set up
setwd("~/forecast_hub/forecasting_deaths")
Sys.setlocale(category = "LC_TIME", locale = "English")
source("functions.R")
```

## prepare data

```{r}
cases_raw <- read.csv("./data-truth/truth_RKI-Incident Cases by Age_Germany.csv")
deaths_raw <- read.csv("./data-truth/truth_RKI-Incident Deaths by Age_Germany.csv")

# restrict to Germany and useful columns only
cases <- subset(cases_raw, location_name=="Germany", select=c(date, age_group, value))
deaths <- subset(deaths_raw, location_name=="Germany", select=c(date, age_group, value))

# reset index
row.names(cases) <- NULL
row.names(deaths) <- NULL

# get age groups
age_groups <- unname(unlist(unique(deaths["age_group"])))
age_groups

# get time series in wide format / age groups in rows
cases_wide <- setNames(reshape(cases, idvar="date", timevar="age_group", direction = "wide"), c("date", age_groups))
deaths_wide <- setNames(reshape(deaths, idvar="date", timevar="age_group", direction = "wide"), c("date", age_groups))

cases_wide$date <- as.Date(cases_wide$date)
deaths_wide$date <- as.Date(deaths_wide$date)

row.names(cases_wide) <- NULL
row.names(deaths_wide) <- NULL
```

```{r}
matplot(cases_wide[-1:-150,"date"], cases_wide[-1:-150,ag], type="l")
matplot(deaths_wide[-1:-150,"date"], deaths_wide[-1:-150,ag], type="l")

```


## forecast deaths


```{r}

#' Evaluate WIS of a negative binomial distribution
#' @param x the vector of observations
#' @param size the vector of size parameters of the negative binomial distribution
#' @param mu the vector of expectations of the negative binomial distribution
#' @param p the vector of quantile levels used in the computation of the WIS
wis_nb <- function(x, size, mu, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){
  # check input
  # print(paste(size, mu))
  if(any(mu <= 0) | any(size <= 0)) stop("mu and size need to be positive.")
  if(length(mu) == 1) mu <- rep(mu, length(x))
  if(length(size) == 1) size <- rep(size, length(x))
  if(length(mu) != length(x) | length(size) != length(x)) stop("mu and size need to be either of length 1 or the same length as x.")  
  # function to evaluate wis for x[i] and parameters mu[i] and size[i]
  wis_nb.i <- function(i){
    # compute quantiles
    q <- qnbinom(p, mu = mu[i], size = size[i])
    # evaluate WIS (see eq 4 here https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618#sec001)
    mean(2*((x[i] <= q) - p)*(q - x[i]))
  }  
  # apply to vector
  sapply(seq_along(x), wis_nb.i)
}


fit_params <- function(cases_lagged, deaths_truth, init_values, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){
    
  wis_sum <- function(par){
    # retransform with exp to render params positive
    size <- exp(par["log_size"])
    cfr <- exp(par["log_cfr"])

    # estimate deaths with case fatality rate (cfr)
    deaths_pred = cfr * cases_lagged
    # deaths_pred = covariates %*% par[-1]
    
    # print(paste(size, cfr, cases_lagged, deaths_pred))
    
    sum(wis_nb(x = deaths_truth, mu = deaths_pred, size = size, p = p))
  }
  
  # initial values (log-transformed)
  if (any(is.na(init_values))){
    log_size_start <- log(3)
    log_cfr_start <- log(0.05)
  } else {
    log_size_start <- log(init_values[1])
    log_cfr_start <- log(init_values[2])
  }
  
  # lower bounds
  # lb_size <- 10^-6
  # lb_cfr <- 10^-6
  # lower_bounds <- c(lb_size,lb_cfr)
  # upper bounds
  # ub_size <- 
  # ub_cfr <- 
  
  # optimization
  # params are log-transformed 
  opt <- optim(par = c(log_size = log_size_start, log_cfr = log_cfr_start), fn = wis_sum)#,method="BFGS") #method="L-BFGS-B", lower=lower_bounds)
  
  # retransform
  opt$par <- exp(opt$par)
  
  return(opt)
}
```


```{r}
boxplot(cases_wide[-1:-150,2:dim(cases_wide)[2]], main="cases sep-mar")
boxplot(deaths_wide[-1:-150,2:dim(cases_wide)[2]], main="deaths sep-mar")

```

```{r}
#' prepare case and death data frames for training:
#' filter age_group, dates, calculate rolsum 
#' @param age_group: specific age group to fit parameters for
#' @param cases_frame: data frame of date and age group columns with case values
#' @param deaths_frame: data frame of date and age group columns with death values
#' @param start: specific starting date for cases and deaths time series
#' @param end: specific end date or NA for last entry of time series
#' @param window: window size for rolling sums of time series 
#' @return processed case and death data frame
prepare_data <- function(ag, cases_frame, deaths_frame, start, end, window){
  
  # set end date to last available date if end == NA 
  if(is.na(end)){end <- cases_frame[dim(cases_frame)[1],"date"]}
  
  # sanity check
  if(end<=start){stop("start of training period must be before end of training period")}
  
  # truncate data to training period
  cases_trunc <- cases_frame[cases_frame[,"date"]>=start & cases_frame[,"date"]<=end,]
  deaths_trunc <- deaths_frame[deaths_frame[,"date"]>=start & deaths_frame[,"date"]<=end,]
  
  # subset date and age group
  cases_ <- cases_trunc[,c("date",ag)]
  deaths_ <- deaths_trunc[,c("date",ag)]
  
  # compute rolling sums; first window-1 dates are excluded
  start_after_rolsum <- start+window-1
  cases_[cases_[,"date"]>=(start_after_rolsum),ag] <- rolling_sum(cases_[,ag], window = window)
  deaths_[deaths_[,"date"]>=(start_after_rolsum),ag] <- rolling_sum(deaths_[,ag], window = window)
  cases_ <- cases_[cases_[,"date"]>=(start_after_rolsum),]
  deaths_ <- deaths_[deaths_[,"date"]>=(start_after_rolsum),]
  
  return(list("cases"=cases_, "deaths"=deaths_))

}

#' get training tuples (lagged case, death on Saturday) 
#' @param lag: number of days cases are lagged against deaths
#' @param cases_: cases returned from function prepare_data
#' @param deaths_: deaths returned from function prepare_data
#' @param dates_excluded: dates to be excluded from training data
#' @param start_after_rolsum: starting date after taking the rolsum
#' @return training tuples (cases lagged by lag param, feasible deaths on Saturday) 
get_lagged_train_data <- function(lag, cases_, deaths_, dates_excluded, start_after_rolsum){
  # based on current lag values, compute feasible death forecast Saturdays
  saturdays <- weekdays(deaths_[,"date"]) == "Saturday"
  start_after_rolsum <- 
  deaths_sat <- deaths_[saturdays & deaths_[,"date"] >= (start_after_rolsum+lag),]
  
  # compute lagged cases corresponding to deaths on saturday
  cases_lagged_dates <- deaths_sat[,"date"]-lag
  cases_lagged <- cases_[cases_[,"date"] %in% cases_lagged_dates,]
  
  ## exclusion of time period
  # exclude deaths and cases based on deaths in exclusion period
  # (also captures cases before period that correspond to deaths in period)
  deaths_sat_ex <- deaths_sat[!(deaths_sat[,"date"] %in% dates_excluded),]
  cases_lagged_ex <- cases_lagged[!(deaths_sat[,"date"] %in% dates_excluded),]
  # exclude deaths and cases based on cases in exclusion period
  # (also captures deaths after period that correspond to cases in period)
  deaths_sat_ex <- deaths_sat_ex[!(cases_lagged_ex[,"date"] %in% dates_excluded),]
  cases_lagged_ex <- cases_lagged_ex[!(cases_lagged_ex[,"date"] %in% dates_excluded),]
  
  # get time series without dates
  cases_lagged_ts <- cases_lagged[,-1]
  deaths_sat_ts <- deaths_sat[,-1]
  
  return(list("cases"=cases_lagged_ts, "deaths"=deaths_sat_ts))
}
```


```{r}
#' fit forecast parameters for individual age group on specific training period
#' parameters to be fitted: lag, size of negat. binom. distr., case fatality rate (cfr)
#' @param age_group: specific age group to fit parameters for
#' @param lags: vector of possible values to lag case series against death series
#' @param cases_frame: data frame of date and age group columns with case values
#' @param deaths_frame: data frame of date and age group columns with death values
#' @param start: specific starting date for cases and deaths time series
#' @param end: specific end date or NA for last entry of time series
#' @param start_exclude: specific starting date for period to exclude 
#' @param end_exclude: specific end date for period to exclude
#' @param window: window size for rolling sums of time series 
#' @param param_names: names of parameters to be fitted
#' @param print_plot: whether to print fitting progress and plot results  
#' @return optimal values of parameters for age group
fit_params_ag <- function(age_group, lags, cases_frame, deaths_frame, start, end, start_exclude, end_exclude, window, param_names, print_plot=T){

  # preprocess data frames
  ret <- prepare_data(ag, cases_frame, deaths_frame, start, end, window)
  cases_ <- ret$cases
  deaths_ <- ret$deaths
  start_after_rolsum <- start+window-1
  
  # sanity checks for period to exclude
  training_period <- seq(start, end, by="days")
  if(end_exclude<=start_exclude){stop("start of excluded period must be before end of excluded period")}
  dates_excluded <- seq(start_exclude, end_exclude, by="days")
  if(!all(dates_excluded %in% training_period)){stop("not all dates to exclude are contained in training period")}
  
  # save param values and objective value per lag
  results <- matrix(data = NA, nrow=length(lags), ncol=length(param_names)+1) 
  colnames(results) <- c(param_names, "value")
  
  # iterate over lag space
  for (i in 1:length(lags)){
    lag <- lags[i]
    
    train_data <- get_lagged_train_data(lag, cases_, deaths_, dates_excluded, start_after_rolsum)
    
    cases_lagged_ts <- train_data$cases
    deaths_sat_ts <- train_data$deaths
    
    stopifnot(length(cases_lagged_ts) == length(deaths_sat_ts))
    if(print_plot){print(paste("Fitting on", length(cases_lagged_ts), "data points."))}
    
    # starting values for optimization
    if (i >= 2){
      init_values <- results[i,c("size", "cfr")]
    } else {
      init_values <- NA
    }
    
    # compute parameters
    res <- fit_params(cases_lagged_ts, deaths_sat_ts, init_values)
    
    # save results
    results[i,] <- c(lag, res$par, res$value)
  }
  
  ag_best_params <- results[which.min(results[,"value"]),]
  
  if(print_plot){print(results)}
  
  if(print_plot){plot(results[,"lag"], results[,"value"], type="b", main = ag)}
  
  if(print_plot){print(ag_best_params)}
  
  return(ag_best_params)
}
```

## calculate best param values for ONE age group

```{r}
## function arguments ########
# age group
ag_nr <- 6
ag <- age_groups[ag_nr]
# set of lags to optimize over
lags <- 15:25
# window for rolling sum (smoothing)
window <- 7
# select training period 
start <- as.Date("2020-11-01")
end <- as.Date("2021-02-01") #NA # give exact date or NA to choose end of time series
# exclude sequence of dates
start_exclude <- as.Date("2020-12-20")
end_exclude <- as.Date("2021-01-22")
# names of parameters to be fitted
# lag and size are essential; case fatality rate could be complemented by other covariates
param_names <- c("lag", "size", "cfr") # dim of is needed later 
############################

ag_best_params <- fit_params_ag(age_group = ag, lags = lags, 
                    cases_frame = cases_wide, deaths_frame = deaths_wide,
                    start = start, end = end, 
                    start_exclude = start_exclude, end_exclude = end_exclude,
                    window = window, param_names = param_names, print_plot = T)
ag_best_params

```

## calculate best param values for SEVERAL interesting age groups

```{r}
## function arguments ########
# age groups
ags <- c("A35-A59", "A60-A79", "A80+")
# set of lags to optimize over
lags <- 18:18
# window for rolling sum (smoothing)
window <- 7
# select training period 
start <- as.Date("2020-11-01")
end <- as.Date("2021-02-01") #NA # give exact date or NA to choose end of time series
# exclude sequence of dates
start_exclude <- as.Date("2020-12-20")
end_exclude <- as.Date("2021-01-22")
# names of parameters to be fitted
# lag and size are essential; case fatality rate could be complemented by other covariates
param_names <- c("lag", "size", "cfr") # dim of is needed later 
############################


# store best params for all considered groups
best_params <- matrix(nrow = length(ags), ncol = 1+length(param_names)+1)
colnames(best_params) <- c("age_group", param_names, "value")

# iterate over age groups
for (i in 1:length(ags)){
  ag <- ags[i]
  ag_best_params <- fit_params_ag(age_group = ag, lags = lags, 
                    cases_frame = cases_wide, deaths_frame = deaths_wide,
                    start = start, end = end, 
                    start_exclude = start_exclude, end_exclude = end_exclude,
                    window = window, param_names = param_names, print_plot = T)
  best_params[i,"age_group"] <- ag
  best_params[i,-1] <- ag_best_params
} 

best_params

```



```{r}
# calculate death number negat. binom. dist. for given forecast date for one age group
#' @param processed_cases: processed case data frame that was used for fitting
#' @param fc_date: forecast date <= last available case date + lag 
#' @param params: fitted parameters lag, size and case fatality rate 
#' @param p: forecast quantile levels 
#' @return: parameters of nb distribution
get_nb_params <- function(processed_cases, fc_date, params){

  # unpack parameters
  lag <- params[1]
  size <- params[2]
  cfr <- params[3]
  
  # get lagged case count
  end_date <- processed_cases[dim(processed_cases)[1],"date"]
  lag_date <- as.Date(fc_date) - lag
  stopifnot(lag_date <= end_date) # can only forecast lag days into future
  case_count <- processed_cases[processed_cases[,"date"]==lag_date,ag]

  # compute death forecast
  mu <- cfr * case_count

  return(list(mu=mu, size=size))
}

# gets params of nb dist and calculates quantile forecast
#' @param 
#' @param 
#' @param 
#' @return: 
calc_forecast <- function(mu, size, p = c(0.01, 0.025, 1:19/20, 0.975, 0.99)){
  
  # get quantiles according to estimated negative binomial distribution
  q <- qnbinom(p, mu = mu, size = size)
  names(q) <- p 
  
  return(q)
}
```

```{r}
# calculate the death forecast distribution for one age group


horizon <- 18 
fc_date <- as.Date(end + horizon)
fc_date


processed_data <- prepare_data(ag = ag, cases_frame = cases_wide, deaths_frame = deaths_wide, start = start, end = end, window = window)

nb_params <- get_nb_params(processed_cases = processed_data$cases, 
                           fc_date = fc_date, params = ag_best_params)

forecast <- calc_forecast(mu = nb_params$mu, size = nb_params$size)
fc <- forecast

```


```{r}
# visualize forecast

# get processed case and death data
cases_ <- processed_data$cases
deaths_ <- processed_data$deaths
start_after_rolsum <- start+window-1

# truth death data: from start_after_rolsum - fc_date
deaths_truth <- deaths_wide[deaths_wide[,"date"] >= start &  deaths_wide[,"date"] <= fc_date,c("date",ag)]
deaths_truth[deaths_truth[,"date"]>=(start_after_rolsum),ag] <- rolling_sum(deaths_truth[,ag], window = window)



# deaths_w_fc <- rbind(deaths_, c(fc_date, fc["0.5"]))
dates_ <- c(deaths_[dim(deaths_)[1],"date"], fc_date)
upper_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.99"])
lower_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.01"])

plot(deaths_truth, ylim=c(min(0, fc["0.01"]), max(as.integer(max(deaths_[,ag])), fc["0.99"])), main=paste(ag, "Death forecast for", fc_date, "based on data until", end), type="l", ylab="")
points(as.Date(fc_date), fc["0.5"], col="red")
points(as.Date(fc_date), fc["0.01"], col="red")
points(as.Date(fc_date), fc["0.99"], col="red")
poly_dates <- c(deaths_[dim(deaths_)[1],"date"], fc_date, fc_date)
poly_values <- c(deaths_[dim(deaths_)[1],ag], fc["0.99"], fc["0.01"])
polygon(poly_dates, poly_values, col=adjustcolor("red",alpha.f=0.2) , border = FALSE)
lines(dates_, upper_values, col="red")
lines(dates_, lower_values, col="red")

# add shifted cases
lag <- ag_best_params[1]
cases_truth <- cases_wide[cases_wide[,"date"] >= (start-lag) & cases_wide[,"date"] <= (as.Date(fc_date)-lag),c("date",ag)]
cases_truth[cases_truth[,"date"]>=(start_after_rolsum-lag),ag] <- rolling_sum(cases_truth[,ag], window = window)

scale <- max(deaths_truth[,ag])/max(cases_truth[,ag])*0.5
lines(cases_truth[,"date"]+lag, cases_truth[,ag]*scale, col="blue")

legend('topleft',legend=c("True deaths", paste("True cases lagged by",lag)), col=c("black", "blue"), lwd=c(1,1))

```

## estimate pooled forecast distribution (for all age strata)

```{r}
## compute death predictions (mus for nb distr) for every age group for every date in training

# get death numbers for training saturdays and cases lagged by estimated lag

# calculate death forecast (=mu) based on estimated cfr

## take sum of mu vectors over age groups (sum for every forecast date)

## based on pooled truth deaths and pooled mus, fit size param of pooled nb distr

```

## put forecast in hub format












